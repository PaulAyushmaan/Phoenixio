# -*- coding: utf-8 -*-
"""Untitled24.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v1t4vnaovdjjg3z3AJ8z2UMd-F1hoek7
"""

import os
import requests
import time
import json
from bs4 import BeautifulSoup
from IPython.display import Markdown, display
from openai import OpenAI

# Load environment variables in a file called .env
api_key = ''

# Check the key

if not api_key:
    print("No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!")
elif not api_key.startswith("gsk"):
    print("An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook")
elif api_key.strip() != api_key:
    print("An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook")
else:
    print("API key found and looks good so far!")

MAX_REQUESTS_PER_MINUTE = 30
MAX_TOKENS_PER_MINUTE = 6000

openai = OpenAI(api_key=api_key, base_url="https://api.groq.com/openai/v1")
# model_name = "deepseek/deepseek-chat-v3-0324:free"
# model_name = "llama3-8b-8192"
model_name = "llama3-70b-8192"

# If this doesn't work, try Kernel menu >> Restart Kernel and Clear Outputs Of All Cells, then run the cells from the top of this notebook down.
# If it STILL doesn't work (horrors!) then please see the Troubleshooting notebook in this folder for full instructions

with open("/content/video_transcript1.json", "r", encoding="utf-8") as f:
    transcript = json.load(f)

# system_prompt = """You are a helpful and accurate assistant that classifies whether parts of a lecture transcript are on-topic or off-topic.
# You analyze a set of consecutive transcript segments and decide if the middle one belongs to the main lecture content or not.
# Respond only with 'On-topic' or 'Off-topic'."""

# system_prompt = """You are a strict classifier that labels whether the MIDDLE segment of a transcript is ON-TOPIC (i.e., the teacher is teaching the subject with theory, examples, or solving exercises) or OFF-TOPIC (i.e., casual talk, greetings, motivational speech, reading comments, technical delays, jokes, filler, etc.).

# Only classify as ON-TOPIC if the middle segment contains clear educational content like explanation, problem-solving, theory, or exercises.

# Respond only with: On-topic or Off-topic."""

# system_prompt = """
# You are a strict classifier that detects whether the middle chunk of a lecture transcript is ON-TOPIC or OFF-TOPIC.

# - ON-TOPIC means the teacher is actively **teaching**: explaining theory, solving examples, discussing concepts, formulas, diagrams, steps, or exercises related to the subject.

# - OFF-TOPIC includes everything else: greetings, jokes, motivational talk, asking how students are, describing what will be taught later, reading comments, storytelling, or vague announcements — even if the subject name is mentioned.

# Do not assume a chunk is on-topic just because it mentions a chapter or subject. Only label it as ON-TOPIC if actual teaching is happening.

# Respond only with: On-topic or Off-topic.
# """

# system_prompt = """
# You are a strict and precise classifier. Your task is to detect whether the **middle chunk** of a lecture transcript is **ON-TOPIC** or **OFF-TOPIC**.

# Your decision must be based ONLY on whether **actual teaching is happening**.

# ### Definitions:

# - **ON-TOPIC**: The teacher is actively teaching. This includes:
#   - Explaining theory or concepts
#   - Solving examples or exercises
#   - Describing steps, formulas, rules, or diagrams
#   - Giving direct instruction related to the subject

# - **OFF-TOPIC**: Everything else — even if academic terms or chapter names are mentioned.
#   This includes:
#   - Greetings or casual conversation (e.g., “Good morning, everyone”)
#   - Jokes, laughter, or motivational talk
#   - Describing what will be taught later (e.g., “We’ll start photosynthesis today”)
#   - Reading or reacting to student comments
#   - Checking attendance or telling students to like/subscribe
#   - Storytelling, digressions, or filler talk (e.g., “Let me tell you something interesting...”)

# ### Examples:

# OFF-TOPIC:
# - “Welcome back to class! I hope you’re doing great.”
# - “Today we’ll learn Newton’s Laws.”
# - “Last class was amazing. You guys were very interactive.”
# - “Okay I’ll wait for a few more people to join.”

# ON-TOPIC:
# - “Newton’s First Law states that an object will remain at rest or in motion unless acted on by an external force.”
# - “Let’s solve this: If the speed is 20 m/s and time is 5s, then distance = speed × time...”
# - “Now look at this diagram of the digestive system…”

# Do not assume a chunk is ON-TOPIC just because it mentions chapters, subjects, or concepts. Only classify it as ON-TOPIC if **actual teaching** is happening.

# Respond strictly with: **On-topic** or **Off-topic**. No extra explanation.
# """

system_prompt = """You are a strict annotator that always picks the most accurate action tag from a fixed list. You do not explain your answer. You only output the tag that best describes the teacher's behavior in the given transcript chunk.
"""

def build_user_prompt(transcript_chunk):
    return f"""You are an expert transcription labeler for educational lecture videos. Your job is to label each transcript chunk with one of the following **ACTION TAGS**, based on the teacher's behavior and content type:
Available tags:
- Teaching_Explanation – Explaining concepts, theories, definitions, or subject matter.
- Teaching_ProblemSolving – Solving problems, giving examples, working through exercises.
- Teaching_Overview – Describing syllabus structure, units, or study plan.
- Recap_PastClass – Reviewing content from earlier classes or sessions.
- Future_Plan – Previewing upcoming topics or sessions.
- Class_Announcement – Announcing schedule, class time, or syllabus changes.
- Student_Engagement – Reading chat, responding to student messages or questions.
- Motivational_Talk – Giving encouragement, emotional pep talk, or career advice.
- Chitchat_Filler – Greetings, jokes, casual banter, repeating words, or non-academic talk.
- Call_To_Action – Asking to like, share, subscribe, join group, install app, etc.
- Platform_Promotion – Promoting app/Telegram/YouTube or other external links.
- Storytelling_Personal – Sharing unrelated personal or student stories.
- Setup_Technical – Talking about mic, video, stream, or delay issues.

---

Below is a transcript segment from a live online class.

Segment:
{transcript_chunk}

What is the **most accurate action tag** for this segment?
Respond only with the **tag name** from the list above. Do not explain or add anything else.
"""

# Light TPM tracking
token_usage_timestamps = []
MAX_TOKENS_PER_MINUTE = 5500  # add safety buffer

def count_tokens(text):
    return int(len(text.split()) * 1.3)

def enforce_token_limit(current_tokens):
    global token_usage_timestamps
    now = time.time()
    one_min_ago = now - 60

    # Clear old entries
    token_usage_timestamps = [t for t in token_usage_timestamps if t[0] > one_min_ago]

    total_used = sum(t[1] for t in token_usage_timestamps)
    if total_used + current_tokens >= MAX_TOKENS_PER_MINUTE:
        wait_time = 60 - (now - token_usage_timestamps[0][0])
        print(f"⏳ [Tokens] Waiting {wait_time:.1f}s to respect TPM limit...")
        time.sleep(wait_time)

    token_usage_timestamps.append((now, current_tokens))

# Main loop
results = []

for idx in range(len(transcript)):
    # if idx == 0:
    #     chunks = transcript[0:3]
    # elif idx == len(transcript) - 1:
    #     chunks = transcript[-3:]
    # else:
    #     chunks = transcript[idx - 1: idx + 2]

    # user_prompt = build_user_prompt(chunks[0]["text"], chunks[1]["text"], chunks[2]["text"])
    user_prompt = build_user_prompt(transcript[idx]["text"])

    message = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt},
    ]

    # prompt_text = chunks[0]["text"] + chunks[1]["text"] + chunks[2]["text"]
    prompt_text = transcript[idx]["text"]
    estimated_tokens = count_tokens(prompt_text)

    # ✅ TPM check
    enforce_token_limit(estimated_tokens)
    print(f"user prompt for chunk {idx}: {user_prompt}")
    try:
        print(f"⏳ Sending API call for chunk {idx}")
        response = openai.chat.completions.create(
            model=model_name,
            messages=message,
            temperature=0
        )
        prediction = response.choices[0].message.content.strip()
        print(f"✅ API Response for chunk {idx}: {prediction}")
    except Exception as e:
        print(f"⚠️ API Error at chunk {idx}: {e}")
        prediction = "Error"

    results.append({
        "chunk_id": transcript[idx]["chunk_id"],
        "start": transcript[idx]["start"],
        "end": transcript[idx]["end"],
        "text": transcript[idx]["text"],
        "action_tag": prediction
    })

    time.sleep(2.5)  # ✅ fixed sleep buffer

# print(results)

# Chunk Filtering Logic:
#
# 1. ALWAYS_KEEP Tags:
#    - These are core teaching actions (e.g., explanation, problem-solving).
#    - By default, these chunks are always marked as keep = True.
#    - However, after initial marking, we remove any teaching chunk that is
#      surrounded by non-teaching chunks on both sides (isolated teaching).
#
# 2. TOLERATE_IF_SANDWICHED Tags:
#    - These are non-teaching but tolerable if they occur between two teaching chunks.
#    - Only marked as keep = True if both previous and next chunks are in ALWAYS_KEEP.
#
# Final Step:
# - After initial labeling, a second pass removes any isolated teaching chunks
#   (those marked as ALWAYS_KEEP but surrounded by non-kept chunks).

ALWAYS_KEEP = {
    "Teaching_Explanation",
    "Teaching_ProblemSolving",
    "Teaching_Overview",
    "Recap_PastClass"
}

TOLERATE_IF_SANDWICHED = {
    "Future_Plan",
    "Student_Engagement",
    "Class_Announcement",
    "Motivational_Talk",
    "Chitchat_Filler",
    "Call_To_Action",
    "Platform_Promotion",
    "Storytelling_Personal",
    "Setup_Technical"
}

def mark_keep_chunks(tagged_chunks):
    result = []

    for i in range(len(tagged_chunks)):
        tag = tagged_chunks[i]["action_tag"]
        keep = False

        prev_tag = tagged_chunks[i - 1]["action_tag"] if i > 0 else None
        next_tag = tagged_chunks[i + 1]["action_tag"] if i < len(tagged_chunks) - 1 else None

        # Always keep if it's core teaching
        if tag in ALWAYS_KEEP:
            keep = True

        # Tolerate only if sandwiched between teaching chunks
        else:
            if prev_tag in ALWAYS_KEEP and next_tag in ALWAYS_KEEP:
                keep = True

        # Append initial decision
        result.append({
            **tagged_chunks[i],
            "keep": keep
        })

    # Remove isolated teaching chunks surrounded by non-teaching
    for i in range(1, len(result) - 1):
        if (
            result[i]["keep"] == True and
            result[i]["action_tag"] in ALWAYS_KEEP and
            result[i - 1]["keep"] == False and
            result[i + 1]["keep"] == False
        ):
            result[i]["keep"] = False

    return result

result = mark_keep_chunks(results)

# Save results to JSON
with open("on_off_topic_classification3.json", "w", encoding="utf-8") as outfile:
    json.dump(result, outfile, indent=2, ensure_ascii=False)

print("✅ Results saved to 'on_off_topic_classification3.json'")

from datetime import timedelta

def timestamp_to_seconds(ts):
    """Converts a timestamp string like '00:01:30.25' to total seconds as float."""
    try:
        h, m, s = ts.split(':')
        return int(h) * 3600 + int(m) * 60 + float(s)
    except:
        return 0.0

def calculate_kept_duration(tagged_chunks):
    """
    Calculates total duration of chunks marked as keep=True.
    Handles both numeric and HH:MM:SS.ms timestamp formats.
    """
    total_duration = 0.0

    for chunk in tagged_chunks:
        if chunk.get("keep"):
            try:
                start = chunk.get("start", 0)
                end = chunk.get("end", 0)

                # Convert if in HH:MM:SS or string format
                if isinstance(start, str):
                    start = timestamp_to_seconds(start)
                if isinstance(end, str):
                    end = timestamp_to_seconds(end)

                total_duration += max(0, end - start)
            except Exception as e:
                print(f"⚠️ Error processing chunk {chunk.get('chunk_id')}: {e}")

    return round(total_duration, 2)

calculate_kept_duration(result)

def analyze_removed_segments(tagged_chunks):
    """
    Analyze non-kept segments:
    - Total number of non-kept chunks
    - Total duration of removed content
    - Number of interruptions (contiguous non-kept blocks)
    """
    removed_duration = 0.0
    removed_chunks = 0
    interruptions = 0
    in_removal_block = False

    for chunk in tagged_chunks:
        keep = chunk.get("keep", False)

        if not keep:
            removed_chunks += 1

            # Parse timestamps
            start = chunk.get("start", 0)
            end = chunk.get("end", 0)

            if isinstance(start, str):
                start = timestamp_to_seconds(start)
            if isinstance(end, str):
                end = timestamp_to_seconds(end)

            removed_duration += max(0, end - start)

            # Count interruption block
            if not in_removal_block:
                interruptions += 1
                in_removal_block = True
        else:
            in_removal_block = False

    return {
        "removed_chunks": removed_chunks,
        "removed_duration_sec": round(removed_duration, 2),
        "interruptions": interruptions
    }

analyze_removed_segments(result)

def get_segment_decisions(tagged_chunks):
    """
    Returns a list of time intervals with KEEP / CUT label.
    Example:
    00:00:00 - 00:00:15 KEEP
    00:00:15 - 00:00:30 CUT
    """
    output = []

    for chunk in tagged_chunks:
        start = chunk.get("start", "0")
        end = chunk.get("end", "0")
        keep = chunk.get("keep", False)

        label = "KEEP" if keep else "CUT"
        output.append(f"{start} - {end} {label}")

    return output

get_segment_decisions(result)